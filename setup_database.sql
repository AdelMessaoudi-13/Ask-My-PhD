-- =====================================================
-- Database Setup for PDF RAG Processor
-- Compatible with pdf_rag_processor.py
-- =====================================================

-- Clean up existing objects if they exist
drop function if exists match_document_chunks(vector, integer, jsonb);
drop table if exists document_chunks;

-- Enable the pgvector extension for vector similarity search
create extension if not exists vector;

-- =====================================================
-- Main table for storing processed document chunks
-- =====================================================
create table document_chunks (
    id bigserial primary key,
    chapter varchar not null,               -- Chapter name/title (e.g., "Chapitre 1 : Introduction")
    chunk_number integer not null,          -- Position of chunk in document (0, 1, 2, ...)
    title varchar not null,                 -- Title generated by GPT-4
    summary varchar not null,               -- Summary generated by GPT-4
    content text not null,                  -- Original chunk content from PDF
    metadata jsonb not null default '{}'::jsonb,  -- Flexible metadata (PDF filename, source, etc.)
    embedding vector(1536),                 -- OpenAI text-embedding-3-small vectors

    -- Prevent duplicate chunks per chapter
    unique(chapter, chunk_number)
);

-- =====================================================
-- Performance indexes
-- =====================================================

-- Vector similarity search index (for semantic search)
create index idx_document_chunks_embedding on document_chunks
using ivfflat (embedding vector_cosine_ops);

-- Metadata filtering index (for filtering by PDF type, source, etc.)
create index idx_document_chunks_metadata on document_chunks
using gin (metadata);

-- Chunk number index for ordering
create index idx_document_chunks_chunk_number on document_chunks (chunk_number);

-- Chapter index for filtering by chapter
create index idx_document_chunks_chapter on document_chunks (chapter);

-- =====================================================
-- Search function for RAG queries
-- =====================================================
create or replace function match_document_chunks (
  query_embedding vector(1536),
  match_count int default 10,
  filter jsonb default '{}'::jsonb
) returns table (
  id bigint,
  chapter varchar,
  chunk_number integer,
  title varchar,
  summary varchar,
  content text,
  metadata jsonb,
  similarity float
)
language plpgsql
as $$
#variable_conflict use_column
begin
  return query
  select
    document_chunks.id,
    document_chunks.chapter,
    document_chunks.chunk_number,
    document_chunks.title,
    document_chunks.summary,
    document_chunks.content,
    document_chunks.metadata,
    1 - (document_chunks.embedding <=> query_embedding) as similarity
  from document_chunks
  where document_chunks.metadata @> filter
  order by document_chunks.embedding <=> query_embedding
  limit match_count;
end;
$$;

-- =====================================================
-- Supabase Security (Row Level Security)
-- =====================================================

-- Enable RLS on the table
alter table document_chunks enable row level security;

-- Allow public read access (adjust based on your security needs)
create policy "Allow public read access"
  on document_chunks
  for select
  to public
  using (true);

-- Allow authenticated users to insert (adjust based on your security needs)
create policy "Allow authenticated insert"
  on document_chunks
  for insert
  to authenticated
  with check (true);
